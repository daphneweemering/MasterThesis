---
title: Interim sample size reestimation for adequately powered series of N-of-1 trials
author:
- name: Daphne N. Weemering*
  num: a
address:
- num: a
  org: Department of Methodology and Statistics, Utrecht University, Utrecht, The Netherlands
corres: "*Corresponding author name, This is sample corresponding address. \\email{authorone@gmail.com}"
presentaddress: Padualaan 14, 3584 CH Utrecht, The Netherlands
authormark: Daphne N. Weemering
articletype: Research article
received: 2022-05-09
revised: 2022-05-09
accepted: 2022-05-09
abstract: "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean ut elit odio. Donec fermentum tellus neque, vitae fringilla orci pretium vitae. Fusce maximus finibus facilisis. Donec ut ullamcorper turpis. Donec ut porta ipsum. Nullam cursus mauris a sapien ornare pulvinar. Aenean malesuada molestie erat quis mattis. Praesent scelerisque posuere faucibus. Praesent nunc nulla, ullamcorper ut ullamcorper sed, molestie ut est. Donec consequat libero nisi, non semper velit vulputate et. Quisque eleifend tincidunt ligula, bibendum finibus massa cursus eget. Curabitur aliquet vehicula quam non pulvinar. Aliquam facilisis tortor nec purus finibus, sit amet elementum eros sodales. Ut porta porttitor vestibulum. Integer molestie, leo ut maximus aliquam, velit dui iaculis nibh, eget hendrerit purus risus sit amet dolor. Sed sed tincidunt ex. Curabitur imperdiet egestas tellus in iaculis. Maecenas ante neque, pretium vel nisl at, lobortis lacinia neque. In gravida elit vel volutpat imperdiet. Sed ut nulla arcu. Proin blandit interdum ex sit amet laoreet. Phasellus efficitur, sem hendrerit mattis dapibus, nunc tellus ornare nisi, nec eleifend enim nibh ac ipsum. Aenean tincidunt nisl sit amet facilisis faucibus. Donec odio erat, bibendum eu imperdiet sed, gravida luctus turpis."
keywords: N-of-1 trials; sample size reestimation; simulation study; statistical methods;
bibliography: bibfile.bib
output:
  bookdown::pdf_book:
    base_format: rticles::sim_article
    includes:
      after_body: appendix.tex
header_includes: 
 - \usepackage{float}
 - \floatplacement{figure}{H!}
 - \usepackage{booktabs}
---

# Introduction 
Randomized controlled trials (RCTs) are considered the gold standard in determining treatment efficacy in healthcare. At first glance, these standard RCTs seem to earn their position as the randomization of patients into a parallel experimental and control condition works quite well in balancing factors that are not under experimental control, allowing for unbiased estimation of the population treatment effect. A drawback, however, is that these standard RCTs require a relatively large sample size to establish the effectiveness of treatment with sufficient power. For the instances of finding the right intervention for patients with rare diseases, i.e., small patient populations, standard RCTs become therefore unfeasible. 

The N-of-1 trial design can offer a solution for clinical research in small patient populations. A N-of-1 trial is a randomized controlled multiple crossover trial where a single patient repeatedly receives the experimental and control intervention in multiple cycles, where the allocation of the interventions in each cycle is in a random order [@guyatt1986]. As the experiment is conducted within a single patient, the advantage of the N-of-1 trial is that a patient-specific treatment effect estimate is obtained. This allows these single patient trials to identify the best treatment for each patient [@kravitz2004].  
N-of-1 trials are suitable in the case the following requirements are met. First, the medical condition for which the intervention is prescribed should be chronic and (relatively) stable over time in order to reduce the chance that the progression of the disease can obscure the treatment differences between and within the trial cycles [@johnston2004; @nikles2011]. Moreover, the intervention being tested in the N-of-1 trial should have a rapid on- and offset of biological action, and should have a short half-life to ensure that there is rapid washout as the cycles alternate [@nikles2011]. Additionally, the effect of the intervention should be measured using a validated (clinical) outcome measure (e.g., choosing the right scale ensuring that real benefits and real burdens are being measured). Lastly, the intervention used in the study should not alter the underlying condition, as this will make it unable to interpret the results for an individual as the trial progresses [@nikles2011]. This all necessitates careful selection of participants, short time cycles and relatively stable symptoms. 

As results of a single N-of-1 trial are specific to an individual patient and can therefore not be generalized to the population, a single N-of-1 trial does not compare itself with a standard RCT. However, combining several individual N-of-1 trials, under the condition that the trials are identical, creates the possibility to estimate the population-level treatment effect [@zucker1997]. In the combined analysis of separate N-of-1 trials, now referred to a series of N-of-1 trials, both the magnitude of the average treatment effect as well as the heterogeneity in treatment response are taken into account [@zucker1997]. Comparing multiple treatment cycles combined with the recognition that the variability in response within individuals is typically lower than the variability between individuals, a smaller sample size is required to detect an effect of treatment in series of N-of-1 trials compared to parallel RCTs [@nikles2011]. This makes series of N-of-1 trials a valuable alternative to standard RCTs in the accumulation of a comprehensive evidence base in populations of people with rare diseases. 

[]: # NOT ENTIRELY SATISFIED WITH THIS PART -- REWRITE A BIT
These series of N-of-1 trials have been performed for, among others, studying the effect of mexiletine on nondystrophic myotonia [@stunnenberg2018], studying the effectiveness of methylphenidate on fatigue in patients with end-stage cancer [@mitchell2015], and for investigating the usefulness of sildenafil on Raynaus-Phenomenon patients [@roustit2018]. Reasons for choosing the N-of-1 trial methodology vary, in general but also specifically for these aforementioned studies. The latter study chose to conduct a series of N-of-1 trials due to the heterogeneity in treatment response that should be taken into account, whereas the first two studies chose the N-of-1 trial methodology due to inability to achieve the required sample size for a standard RCT. 

As in any clinical study, a priori sample size determination is necessary to avoid under- or overpowering the study, for planning on allocating resources and for assessing the feasibility of the study. Sample size formulas have been derived for series of N-of-1 trials for both random and fixed effects models [@senn2019]. As the main objective of combining the results of separate N-of-1 trials is to make inferences regarding the population treatment effect, random effects models are most appropriate and of interest here. For the sample size calculations, assumptions have to be made with regard to the parameters in the model, such as the clinically relevant difference and the nuisance parameters. However, the nuisance parameters in the model, which concern the within- and between subject variance of the response to treatment for series of N-of-1 trials [@araujo2016], are generally unknown at the start of the study. Taking estimates of nuisance parameters from other studies can be unreliable because of differences in the study population, background conditions or study design [@zucker2002]. Furthermore, an estimate of the between subject variance in treatment response is often not available because the kind of study to obtain these estimates is a trial (or trials) incorporating such a component, such as a series of N-of-1 trials [@senn2016]. Series of N-of-1 trials are not (yet) that common, and even if similar series of N-of-1 trials exist, these kinds of estimates are usually not reported in the literature. Making unrealistic assumptions for these nuisance parameters can lead to substantial over- or underpowering, where the former exposes too many patients to potentially inferior treatment and the latter increases the risk of failing to identify a clinically relevant treatment effect due to a lack of power.

An appealing strategy for conquering the problem of incorrect assumptions for unknown parameters in sample size calculations is a two-stage design with interim sample size reestimation based on nuisance parameter estimates. With this design, the initially required sample size is calculated by making reasonable assumptions for the unknown nuisance parameters. Then, a portion of the data is collected up until a prespecified interim point along the trial and the unknown nuisance parameters are estimated using the data observed so far. These estimates are then used to update the power analysis and to adjust the sample size. Subsequently, the study is continued until the adjusted sample size is reached, and finally, the hypothesis is tested with all the data [@proschan2005]. Simulations studies have shown that this method has a high potential to protect from an incorrect sample size if the nuisance parameters where misspecified at the design stage of the study for standard RCTs [@wittes1990]. A distinction can be made between interim sample size reestimation based on nuisance parameter estimates and based on treatment effect estimates [@proschan2009]. This thesis will cover the first approach. 

A concern with interim sample size reestimation based on estimates of nuisance parameters, is the inflation of the type I error rate [@kieser2000; @wittes1990; @birkett1994]. Investigating the influence of interim sample size reestimation for series of N-of-1 trials on the type I error rate is not the main objective of this thesis. However, it will be assessed whether the type I error rate becomes inflated for the proposed method considered here, allowing future research to build upon these results. 

The application of interim sample size reestimation has not yet been investigated in the context of series of N-of-1 trials and no specific guidelines have been established. With this thesis, the usefulness and feasibility of interim sample size reestimation in series of N-of-1 trials will be investigated. With the use of simulation studies, interim sample size reestimation in series of N-of-1 trials will be compared with a similar design having a fixed sample size. Furthermore, the type I error rate for series of N-of-1 trials with interim sample size reestimation will be evaluated. Finally, the minimally required sample size that is necessary for reliable interim sample size reestimation will be determined.

The remainder of this thesis will be structured as follows: In section \@ref(methods), notation, sample size calculations for series of N-of-1 trials, and the model that is used for the simulation studies are discussed. In section \@ref(simulations) the design of the simulation studies in which power, type I error rate and the expected sample size are evaluated will be explained. Section \@ref(results) discusses the results of the simulations studies. And finally, this thesis is concluded with a discussion which is outlined in section \@ref(discussion). 

# Methodology {#methods}
First, the methodology of a one-stage design for series of N-of-1 trials will be discussed in section \@ref(onestage), in which notation, the model used and sample size calculations for series of N-of-1 trials are introduced. In section \@ref(twostage), the procedure for interim sample size reestimation in series of N-of-1 trials will be outlined. 

## One-stage design {#onestage}
In a series of N-of-1 trials, each of the $n$ subjects receives the experimental condition in one period and the control condition in the other period, each in $k$ cycles of two periods. The order of treatment administration within each cycle will be randomly determined. At the end of each period, the outcome $Y_{ijt}$ is measured, indicating the outcome for patient $i$ ($i = 1, ..., n$) in cycle $j$ ($j = 1, ..., k$) who is given treatment $t$ ($t = 1, 2$). It is assumed that the disease under study is stable over time, that carryover effects are absent because of a sufficient duration of the washout period, and that there are no missing data. Furthermore, it is assumed that the outcome is a continuous measure and that it is normally distributed according to the following model:

\begin{equation}
Y_{ijt} = \lambda_i + \beta_{ij} + \epsilon_{ijt} + Z_{ijt}\tau_i
\end{equation}

In this model [@araujo2016], $\lambda_i \sim N(\Lambda, \phi^2)$ represents the random effect for subject $i$, $\beta_{ij} \sim N(0, \gamma^2)$ indicates he cycle effects for subject $i$ in cycle $j$, $\epsilon_{ijt} \sim N(0, \sigma^2)$ represents the $i$-th subject's random error for the $j$-th cycle and treatment $t$, and finally $\tau_i \sim N(T, \psi^2)$ indicates the treatment effect for subject $i$. $Z_{ij1} = \frac{1}{2}$ and $Z_{ij2} = -\frac{1}{2}$, indicating the received treatment for patient $i$ in cycle $j$. In this model, all the nuisance parameters are assumed to be independent of each other. 

However, under the assumption that the data is complete, a simpler model for the treatment differences for subject $i$ in cycle $j$ can be derived from equation 1 by subtracting the values from the first period in every cycle from the second period in the cycle, and subsequently divide by $(Z_{ij1} - Z_{ij2})$ [@araujo2016]:

\begin{equation}
d_{ij} = \tau_i + \epsilon_{ij}
\end{equation}

Here, $d_{ij}$ represents the observed treatment difference for patient $i$ in cycle $j$, where treatment 1 is consistently subtracted from treatment 2. In this model, $\tau_i \sim N(T, \psi^2)$, as before and $\epsilon_{ij} \sim N(0, 2\sigma^2)$. $\tau_i$ is the random treatment effect for patient $i$, and $\epsilon_{ij}$ are random within-subject within-cycle disturbance terms. These disturbance terms are assumed to be i.i.d. (independent and identically distributed) both across cycles and across patients. Furthermore, $\tau_i$ and $\epsilon_{ij}$ are assumed to be independent of each other. The variance term of $\epsilon_{ij}$, $2\sigma^2$, is given to make this model compatible with a mixed model using the original observations [@senn2019]. 

### Sample size calculations in N-of-1 trials
From the model of the treatment differences in equation 2, the average treatment effect in the population and the corresponding variance can be derived, both necessary for calculating the required sample size. Following Senn [@senn2019], an average treatment effect for each patient can be obtained:

\begin{equation}
\bar{d_{i.}} = \frac{\sum_{j=1}^{k} d_{ij}}{k}
\end{equation}

The average over all the $n$ averages is equal to $\hat{T} = \sum_{i=1}^{n} \sum_{j=1}^{k} d_{ij}/ nk$, which can be used to test the differences between the two treatments under investigation. This estimate has a variance of $var(\hat{T}) = \psi^2 + 2\sigma^2 / kn$. The variance at the patient level, the variance of the $n$ estimates of $\bar{d_{i.}}$, is then defined as:

\begin{equation}
var(\bar{d_{i.}}) = \psi^2 + 2\sigma^2 /k
\end{equation}

This estimate has $(n-1)$ degrees of freedom [@senn2019] and can be used to calculate the required sample size to achieve the desired power under hypothesized values for the nuisance parameters, $\psi^2$ and $\sigma^2$, now denoted as $\psi^2_h$ and $\sigma^2_h$, the clinically relevant difference $\Delta$, and the two-sided significance level $\alpha$ using a one sample $t$-test. For the calculation of the sample size, the standard deviation of the estimate in equation 4 is used. The exact formula for the calculation of the sample size is based on a non-central $t$-distribution. Computation of the sample size therefore requires an iterative process and this can straightforwardly be done with the ```pwr.t.test``` function of the ```pwr``` package [@champely2018] in ```R``` [@Rmanual]. 

## Two-stage design {#twostage}
To cope with the problem around the a priori uncertainty regarding the nuisance parameters in the model, interim sample size reestimation is applied. For this process, the following steps are taken [@wittes1990; @kieser2000; @coffey1999]:

1. Specify the clinically relevant difference ($\Delta$), the type I error rate ($\alpha$), the desired power ($1-\beta$), the proportion of the initial sample size on which interim sample size reestimation will be based ($f$) and the a priori hypothesized estimates for the nuisance parameters ($\psi^2_h$ and $\sigma^2_h$). 
2. Use $\psi^2_h$ and $\sigma^2_h$ to estimate the initial sample size $n_{init}$ that yields the desired level of power. All sample sizes are rounded up. 
3. Use $f n_{init} = n_{frac}$, the initial sample size on which interim sample size reestimation is based, to estimate $\hat{\sigma}^2$ and $\hat{\psi}^2$. 
4. Then, use $\hat{\sigma}^2$ and $\hat{\psi}^2$ to find the new total sample size, $n_{final}$, that is needed to achieve the target power and subsequently observe the additional $n_{final}-n_{frac}$ patients. If $n_{final}-n_{frac} \leq 0$, $n_{frac}$ is used as the final sample size. Also, if the effect size (Cohen's $d$, mean treatment difference divided by the standard deviation) for recalculating the sample size at interim becomes larger than 10 due to small $\hat{\sigma}^2$ and $\hat{\psi}^2$, the sample size becomes too small. In that case, the effect size will be set equal to $10$. 
5. Test the hypothesis on all the $n_{frac} + (n_{final}-n_{frac})$ observations.  


# Simulations {#simulations}
Two simulation studies are performed to (I) compare the power and average sample size of trials incorporating interim sample size reestimation with series of N-of-1 trials having a fixed sample size, and (II) to evaluate the type I error rate for series of N-of-1 trials that incorporate interim sample size reestimation. When the effect of interim sample size reestimation in series of N-of-1 trials on power and the type I error rate is established, the minimally required sample size that is necessary for reliable interim sample size reestimation will be determined. 

The linear mixed model provided in equation 2 will be used to simulate data for a series of N-of-1 trials. For the simulation studies, various scenarios are considered, each under different combinations of $\psi_h^2$, $\sigma_h^2$, $f$, and for the actual values of the nuisance parameters which are used for generating the data, $\psi_t^2$ and $\sigma_t^2$. This eventually results in $3^5 = 243$ different scenarios in each simulation study. All the relevant parameter values considered in the simulation studies are displayed in table 1. 

\begin{table}[h] 
\begin{center}
\caption{Parameters in the two simulation studies.}
\begin{tabular}{p{8cm}p{6cm}} 
\hline
Description & Values \\
\hline 
\textbf{Design parameters} & \\
Fraction of initial sample size & $f = 0.25, 0.5, 0.75$ \\
Cycles per patient & $k = 3$ \\
Power & $1 - \beta = 0.8$ \\
Two-sided nominal significance level & $\alpha = 0.05$ \\
Clinically relevant difference & $\Delta = 0, 1$ \\
\textbf{Model parameters} & \\
Within-patient within-cycle variance (data generation) & $\sigma^2_t = 0.25, 0.5, 1$ \\
Variance of treatment effect (data generation) & $\psi^2_t = 0.5, 1, 2$ \\
Within-patient within-cycle variance (hypothesized) & $\sigma^2_h = 0.25, 0.5, 1$ \\
Variance of treatment effect (hypothesized) & $\psi^2_h = 0.5, 1, 2$ \\
Average treatment effect & $T = \Delta = 0, 1$  \\
\textbf{Simulation parameter} & \\
Number of simulations & $N = 10000$ \\
\hline 
\multicolumn{2}{l}{\textbf{Outcome parameters}} \\
Statistical power & Proportion of iterations that the null hypothesis is rejected under $T = 1$ (for data generation) \\
Type I error rate & Proportion of iterations that the null hypothesis is rejected under $T = 0$ (for data generation) \\
Average sample size & Average sample size under reestimation for the $N$ iterations \\
\hline 
\end{tabular}
\end{center}
\end{table}

In the first simulation study, power will be evaluated and compared between series of N-of-1 trials incorporating interim sample size reestimation and series of N-of-1 trials that have a fixed sample size. Power is computed as the proportion of iterations that the null hypothesis of no treatment effect is rejected ($p \leq \alpha$) when $T = 1$, both for data generation and for calculating the initial sample size. In the second simulation study, the type I error rate, $\alpha$, will be evaluated for series of N-of-1 trials. As $\alpha$ is the probability of falsely rejecting the null hypothesis when it is true [@neyman1933], setting $T = 0$ for data generation and applying the same calculation as for the power, the estimated $\alpha$-level should approximate the nominal rate. Both simulation studies compute the average reestimated sample size, which provides an opportunity to see if there should be certain requirements for the minimum sample size on which re-estimation is based. To do so, the average reestimated sample sizes will be compared with the corresponding true sample size. Power and the type I error rate are also involved in deciding on these requirements; they should at least meet the prespecified $0.8$ and $0.05$, respectively. 

Linear mixed models will be fitted to the simulated data using the ```lme4``` package [@lme4] in ```R``` (version 4.1.3) [@Rmanual]. Because treatment effects are modeled within cycles, an intercept-only model will suffice to estimate the mean treatment effect and patient-specific random effects. Restricted maximum likelihood (REML) will be applied to estimate the variance parameters, as this approach, to the contrary of "regular" maximum likelihood (ML), produces unbiased estimates for the variance components in the model for smaller sample sizes [@corbeil1976]. Sample size calculations for $n_{init}$ and $n_{final}$ will be performed using a two tailed one sample $t$-test from the ```pwr.t.test``` function from the ```pwr``` package in ```R``` [@champely2018]. If the effect size (Cohen's $d$, the standardized effect size) for (re)calculating the sample size becomes larger than 11 due to small $\hat{\sigma}^2$ and $\hat{\psi}^2$, the sample size becomes too small (approximately 2). In that case, the effect size will be set equal to $10$. In all other cases, the calculated Cohen's $d$ will be used. Also, if the reestimated sample size is lower than $f*n$, the trial will be stopped and the final analysis will be performed. For the explanation of the process of interim sample size reestimation, the reader is referred to section \@ref(twostage).  


# Results {#results}

## Power
First, it was examined how series of N-of-1 trials performed, and how they performed compared to series of N-of-1 trials with a fixed sample size, both evaluated in terms of power. Figure 1 (corresponding table A1 can be found in the appendix) displays the power of series of N-of-1 trials under various combinations of hypothesized values for the nuisance parameters ($\psi_h^2$ and $\sigma_h^2$) and under various values for the nuisance parameters for data generation $\psi_t^2$ and $\sigma_t^2$). First of all, underpowering a study appears to be least evident when 75\% of the initial sample size is used to base interim sample size reestimation on. However, an excess of power appears to be problematic for some of these scenarios, especially those scenarios where $\psi_t^2 = 0.5$. Where $\psi_h^2 = 2$ it reaches even a power of 100\%. Overpowering a study might be less of a problem compared to underpowering a study because the results are still reliable, it is still problematic because it is a waste of resources. Especially for studies conducted in populations of patients with rare diseases overpowering a study is not desirable.

When 50\% of the initial sample size is used for reestimation of the sample size, overall power across all the scenarios appears to be adequate with some exceptions. For those scenarios where $\psi_t^2 = 2$ and $\psi_h^2 = 0.5$, and to a lesser extend also where $\psi_t^2 = 2$ and $\psi_h^2 = 1$, a lack of power occurs. However, this deficiency in power remains limited, the lowest power being 72.5\%. Those scenarios where $\psi_t^2 = 0.5$ again result in an excess of power, especially those scenarios where $\psi_h^2 = 2$. It becomes clear that those scenarios where the discrepancy between the population value and the a priori expected value for $\psi^2$ is largest, that those scenarios have the greatest influences on the power. The value of $\sigma_h^2$ appears to have less influence on the power. Overall, it appears that taking 50\% of the initial sample size has the highest chance of having an adequately powered series of N-of-1 trials. 

When 25\% of the initially required sample size is used to base interim sample size reestimation on, the results become less optimistic. Those scenarios where $\psi_t^2 = 2$ and $\psi_h^2 = 0.5$, regardless of the value of $\sigma_h^2$, the power drops to even (approximately) 60\%. The scenarios where $\psi_h^2 = 1$ lead to adequate power only where $\psi_t^2$ is small. The scenarios where $\psi_h^2 = 2$ result in adequately powered series of N-of-1 trials, with the exception of the scenarios where $\psi_t^2 = 2$. 

```{r, include = FALSE}
# Set working directory and load in the data for power in series of N-of-1 trials with interim sample size reestimation
setwd('/Users/daphneweemering/Google Drive/UU/Thesis/MasterThesis/data/Modified data')
load('data-for-plotting-reestimation.RData')
```

```{r, echo = FALSE, fig.cap = 'Power in simulated series of N-of-1 trials with interim sample size reestimation under different data and hypothesized values for the nuisance parameters. The x-axis indicates the different combinations of the nuisance parameters for data generation ($\\psi^2$ and $\\sigma^2$, respectively). The dotted line indicates a power of 0.8.\\label{fig:fig2}', fig.width = 6.8, fig.height = 6.2, fig.align = 'center'}
# Load library
library(ggplot2)

# Make the figure for the power
ggplot(data = results, mapping = aes(x = true_sigma_psi, y = power, shape = hyp_sigma_cat,
                                     color = hyp_psi_cat,)) +
  geom_jitter(position = position_jitter(0.18), size = 2, stroke = 0.8) +
  facet_grid(fraction_cat ~ .) +
  xlab(expression(paste('Values for ', sigma[t]^2, ' and ', psi[t]^2))) +
  ylab('Power') +
  geom_hline(yintercept = 0.8, linetype = "dotted") +
  theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1),
        axis.text.y = element_text(size = 8),
        strip.text.x = element_text(size = 8),
        axis.title = element_text(size = 9.5),
        legend.title = element_text(size = 9.5),
        legend.text = element_text(size = 8)) +
  ylim(0.4, 1) +
  labs(shape = expression(sigma[h]^2), color = expression(psi[h]^2)) +
  scale_shape_manual(values = c(1, 2, 0)) +
  guides(shape = guide_legend(order = 1),
         color = guide_legend(order = 2))
```
Now, the comparison of power between series of N-of-1 trials including interim sample size reestimation with series of N-of-1 trials that have a fixed sample size. Figure 2 (corresponding table A3 can be found in the appendix) shows the power for series of N-of-1 trials with a fixed sample size under various combinations of the hypothesized values for the nuisance parameters and values for the nuisance parameters used for data generation. It becomes immediately apparent that the results for series of N-of-1 trials with a fixed sample size are much more diverse and for some scenarios more problematic. Those scenarios where $\psi_h^2 = 0.5$ and $\sigma_h^2 = 0.25$ even result in studies with less than 40\% power, whereas scenarios where $\psi_h^2 = 2$ will lead to studies with a power of 100\%. The scenarios for the hypothesized nuisance parameters that match the population value result in adequately powered studies, as expected, but almost all the other combinations will result in over- or underpowered studies. 

Compared to series of N-of-1 trials including interim sample size reestimation, the fixed sample size approach can result in fairly over- or underpowered studies. The process of interim sample size reestimation appears to be able to make up for the wrong assumptions that where made prior to the study. Take for instance the scenario where $\psi_t^2 = 0.5$ and $\sigma_t^2 = 1$, and where $\psi_h^2 = 0.5$ and $\sigma_h^2 = 0.25$, quite a moderate scenario where $\sigma^2$ is hypothesized to be lower than it is in the population. If one chooses to take the fixed sample size approach, the power of the study would be 60.8\%. However, taking the two-stage approach with interim sample size reestimation, the sample size is reconsidered somewhere along the trial, and the power is restored to 83.4\% when 75\% of the initial sample size is used to base reestimation on, 80.4\% when 50\% of the initial sample size is used, and 72.7\% when 25\% of the initial sample size is used for reestimation. Using 25\% of the initial sample size to base interim sample size reestimation might still not be optimal, but using 50\% and 75\% of the initial sample size results in most cases to adequately powered studies. 

```{r, include = FALSE}
# Set working directory and load in the data for power in series of N-of-1 trials with a fixed sample size
setwd('/Users/daphneweemering/Google Drive/UU/Thesis/MasterThesis/data/Modified data')
load('data-for-plotting-fixed.RData')
```

```{r, echo = FALSE, fig.cap = 'Power in simulated series of N-of-1 trials with a fixed sample size under different data and hypothesized values for the nuisance parameters. The x-axis indicates the different combinations of the nuisance parameters for data generation ($\\psi^2$ and $\\sigma^2$, respectively). The dotted line indicates a power of 0.8.\\label{fig:fig2}', fig.width = 6.8, fig.height = 4.5, fig.align = 'center'}
# Load library
library(ggplot2)

# Make the figure for the power
ggplot(data = results, mapping = aes(x = true_sigma_psi, y = power_fixed, shape = hyp_sigma_cat,
                                     color = hyp_psi_cat,)) +
  geom_jitter(position = position_jitter(0.18), size = 2, stroke = 0.8) +
  xlab(expression(paste('Values for ', sigma[t]^2, ' and ', psi[t]^2))) +
  ylab('Power') +
  geom_hline(yintercept = 0.8, linetype = "dotted") +
  theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1),
        axis.text.y = element_text(size = 8),
        strip.text.x = element_text(size = 8),
        axis.title = element_text(size = 9.5),
        legend.title = element_text(size = 9.5),
        legend.text = element_text(size = 8)) +
  labs(shape = expression(sigma[h]^2), color = expression(psi[h]^2)) +
  scale_shape_manual(values = c(1, 2, 0)) +
  guides(shape = guide_legend(order = 1),
         color = guide_legend(order = 2))
```

## Type I error rate
Next to evaluating and comparing the power in series of N-of-1 trials, the effect of interim sample size reestimation in this trial design on the type I error rate was evaluated. Figure 3 (corresponding table A3 can be found in the appendix) displays the type I error rates under the various combinations of hypothesized values for the nuisance parameters and values of the nuisance parameters for the data. Where 25\% of the initially required sample size is taken to base interim sample size reestimation on, the type I error rate appears to become inflated under all the scenarios that are considered. For some scenarios, such as the combination of $\psi_t^2 = 0.25$, $\sigma_t^2 = 0.5$, $\psi_h^2 = 2$ and $\sigma_h^2 = 1$, the inflation of $\alpha$ remains limited. However, when 50\% of the initial sample size is used as a basis for interim reestimation of the sample size, the inflation of the type I error rate appears to be limited to a number of scenarios. Where $\psi_h^2$ is hypothesized to be equal to 2, the largest value considered in this thesis, the type I error rate appears to be closest to the nominal $\alpha$ level of $0.05$. A larger value for $\sigma_h^2$ also appears to positively influence the type I error rate, but the value for $\psi_h^2$ seems to have a higher impact. 

When 75\% of the initial sample size is used for reestimation of the sample size at interim, it appears that the scenarios where $\psi_h^2$ is hypothesized to be $0.5$ results in the inflation of the type I error rate. The only scenario where this does not happen, is when $\psi_h^2$ and $\sigma_h^2$ are both small ($0.5$ and $0.25$ respectively) and the discrepancy between hypothesized and true values is thus smallest. For most of the scenarios where $\psi_h^2 = 2$, the type I error rate remains controlled. Where $\psi_h^2 = 1$ it appears that the type I error rate also remains controlled for the scenarios where $\psi_t^2 = 0.5$. The scenarios where $\psi_t^2 = 2$ and $\psi_h^2$ is hypothesized to be smaller than that seems to lead to an inflated type I error rate. 

From these results it becomes clear that the value of $\psi_h^2$ has a greater influence on the inflation of the type I error rate than the value of $\sigma_h^2$. When the discrepancy between true and hypothesized values for $\psi^2$ is large, the type I error rate become (more) inflated. When one applies interim sample size reestimation in the manner that is discussed in this thesis, the total sample size is not a constant but depends on the data that is obtained up until the interim point. A pooled estimate for the nuisance parameters is used to obtain a $t$ statistic, which may cause the $t$ statistic to not be $t$ distributed in this type of design. The discrepancy between true and hypothesized values for $\psi^2$ appears to have the most influence on the type I error rate. If the hypothesized value for $\psi^2$ is small whereas the population value is large(r), the interim estimate in that case deviates a lot from the initial estimate of $\psi^2$. Because of the relatively big discrepancy between $\psi_h^2$ and $\hat{\psi}^2$, the pooled estimate deviates a lot from what it should be. If $\psi_h^2$ and $\hat{\psi}^2$ are close, the pooled estimate remains quite the same to what it would have been under a fixed sample size. 

Taking 25\% of the initial sample size for reestimation also appears to impact the inflation of the type I error rate negatively. Small sample sizes can cause the interim estimates for the nuisance parameters to be relatively unstable, thus creating a larger discrepancy between the hypothesized and interim estimates of the nuisance parameters. 

```{r, include = FALSE}
# Set working directory and load in the data
setwd('/Users/daphneweemering/Google Drive/UU/Thesis/MasterThesis/data/Modified data')
load('data-for-plotting-reestimation.RData')
```

```{r, echo = FALSE, fig.cap = 'Type I error rate in simulated series of N-of-1 trials under different data and hypothesized values for the nuisance parameters. The x-axis indicates the different combinations of the nuisance parameters for data generation ($\\psi^2$ and $\\sigma^2$, respectively). The dotted line indicates the nominal $\\alpha$ level of 0.05. \\label{fig:fig3}', fig.width = 6.8, fig.height = 6.2, fig.align = 'center'}
# Load library
library(ggplot2)

# Make the figure for the type I error rate
ggplot(data = results, mapping = aes(x = true_sigma_psi, y = alpha, color = hyp_psi_cat,
                                     shape = hyp_sigma_cat)) +
  geom_jitter(position = position_jitter(0.18), size = 2, stroke = 0.8) +
  facet_grid(fraction_cat ~ .) +
  xlab(expression(paste('Values for ', sigma[t]^2, ' and ', psi[t]^2))) +
  ylab('Type I error rate') +
  ylim(0, 0.10) +
  geom_hline(yintercept = 0.05, linetype = "dotted") +
  theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1),
        axis.text.y = element_text(size = 8),
        strip.text.x = element_text(size = 8),
        axis.title = element_text(size = 9.5),
        legend.title = element_text(size = 9.5),
        legend.text = element_text(size = 8)) +
  labs(shape = expression(sigma[h]^2), color = expression(psi[h]^2)) +
  scale_shape_manual(values = c(1, 2, 0)) +
  guides(shape = guide_legend(order = 1),
         color = guide_legend(order = 2))

```

# Sample size 
```{r, include = FALSE}
# Set working directory and load in the data
setwd('/Users/daphneweemering/Google Drive/UU/Thesis/MasterThesis/data/Modified data')
load('data-for-plotting-reestimation.RData')
```

```{r, echo = FALSE, message = FALSE, fig.cap = 'Reestimated sample sizes in simulated series of N-of-1 trials under different data, hypothesized values for the nuisance parameters, and fractions of the initial sample size. The dotted line indicates the sample size under the true values for the nuisance parameters.\\label{fig:fig1}', fig.width = 7, fig.height = 6.2, fig.align = 'center'}
# Load libraries
library(ggplot2)
library(dplyr)
library(glue)

ggplot(data = results, mapping = aes(x = fraction_cat, y = median_reestimsampsize, color = hyp_sigma_psi)) +
  facet_grid(glue('psi[t]^2*" = {true_psi_cat}"') ~ glue('sigma[t]^2*" = {true_sigma_cat}"'), labeller = label_parsed) +
  geom_point(position = position_dodge(0.7), size = 2.4, shape = 21) +
  geom_errorbar(aes(ymin = min_reestimsampsize,
                    ymax = max_reestimsampsize), 
                width = 0.5, position = position_dodge(0.7)) +
  xlab('Fraction of the initial sample size (f)') +
  ylab('Reestimated sample size') +
  theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1),
        axis.text.y = element_text(size = 8),
        strip.text.x = element_text(size = 8),
        axis.title = element_text(size = 9.5),
        legend.title = element_text(size = 9.5),
        legend.text = element_text(size = 8)) +
  labs(color = expression(paste(sigma[h]^2, ' and ', psi[h]^2))) +
  geom_hline(data = results, aes(yintercept = hline), linetype = "dotted")
```


# Discussion {#discussion}
The series of N-of-1 trials design offers a rigorous method for minimizing the sample size in clinical trials, offering opportunities for clinical research in populations of people with rare diseases, but also for general clinical research. The required sample size is determined by a number of factors, under which the population nuisance parameters which are, to the contrary of other factors such as type I and II error rates and the clinically relevant effect, generally unknown. There is usually considerable uncertainty about the values that are hypothesized for these unknown parameters. To deal with this problem, this thesis investigated the use of interim sample size reestimation in series of N-of-1 trials to contribute to the improvements of reliable trial methodology in populations of people with rare diseases. With interim sample size reestimation, the variances are estimated during an ongoing trial and those estimates are used to recalculate the sample size to make up for misspecifications prior to the trials. 

In this thesis, two simulation studies are performed to examine the reliability of series of N-of-1 trials in terms of power and the type I error rate, and to compare series of N-of-1 trials including interim sample size reestimation with series of N-of-1 trials that have a fixed sample size. Based on the results for the power and type I error rate, recommendations will be made with regard to the minimally required sample size to base interim reestimation of the sample size on. 

The results indicate that series of N-of-1 trials including interim sample size reestimation have higher power than series of N-of-1 trials with a fixed sample size. Especially for those trials where the misspecification of the nuisance parameters prior to the study was large compared to the population value, interim sample size reestimation in series of N-of-1 trials has a large positive impact on the power of the study in comparison with similar fixed sample size trials. When 50\% or 75\% of the initial sample size is used to base interim sample size reestimation on, almost all scenarios considered in this thesis will lead to a power of the desired 80\% or higher. These scenarios where the power is much higher than 80\% are not desirable. However, compared to the low levels of power for some scenarios of the fixed sample size design, incorporating interim sample size reestimation in series of N-of-1 trials can be a demonstrably improvement.  

The type I error probabilities in series of N-of-1 trials appeared to be inflated for most of the scenarios considered in this thesis. The method of interim sample size reestimation as discussed causes the total sample size to be dependent on the data that is obtained up until the interim point. A pooled estimate for each nuisance parameter is used, which may cause the statistic to not be distributed as expected in this approach [@kieser2000]. Small initial sample sizes can cause the interim estimates of the nuisance parameters to be unreliable. The larger the discrepancy between the interim estimates for the nuisance parameters and the population values, the larger the discrepancy between the pooled estimate and what it should be. For larger initial sample sizes, the interim estimates of the nuisance parameters can be estimated with more reliability, causing higher chances for the pooled estimates to be closer to their true values.  

Considering that the type I error rate is more likely to be controlled at the nominal level when the initial sample size is relatively large, or at least large enough to estimate the nuisance parameters at interim reliably, and that statistical power is also more adequate when a larger fraction of the initial sample size is used to base reestimation on, it appears to be best that the initial sample size is not too small. However, as this research focuses on improving trial designs for clinical research in small populations, it is also desirable to minimize the number of patients to include in a clinical study. For adequately powered series of N-of-1 trials, the minimum sample size for reliable interim sample size reestimation should be at least 20 patients. Then, 50\% of the initial sample size can be used to base interim reestimation on. For smaller sample sizes, 75\% of the initial sample size to base reestimation on will lead to adequately powered series of N-of-1 trials. Notice that it is desirable to take a smaller fraction of the initial sample size for reestimation, as chances of overpowering are higher when a larger fraction of the initial sample size is used and the misspecification of the nuisance parameters is large. The type I error rate may not be controlled at the nominal $\alpha$ level when 50\% or even 75\% of the initial sample size is used for reestimation. Only when the sample size is 20 and 75\% of the initial sample size is used for reestimation, the type I error rate is controlled at the nominal level. Methods to control the bias in the type I error rate at the nominal level exist [@coffey1999; @kieser2000], but not specifically for the series of N-of-1 trials design. This can be an opportunity for future research. 

Some limitations of this study are acknowledged. First of all, only a limited number of design scenarios are discussed here. It was attempted to make the scenarios that are considered in this study as realistic as possible so that these are applicable to real life situations. However, other designs could have different results and implications. Second, practical issues such as carryover effects and selection bias, issues that can significantly influence the results, are not considered in the simulation studies of this paper. Third, and last, this thesis does not investigate the effect of the relationship between the number of patients and the number of cycles within a patient on the sample size. As the number of cycles within a patient is increased, the number of required patients would be expected to decrease. Investigating the relationship between the number of cycles and patients on the sample size and the implications of this relationship on interim sample size reestimation could be very valuable for the development of research in clinical trial designs for populations of patients with rare diseases. 



























